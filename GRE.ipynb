{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graduate Admission Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'D:\\copy of htdocs\\practice\\Python\\200days\\Day175 DL_5\\Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial No.           0\n",
       "GRE Score            0\n",
       "TOEFL Score          0\n",
       "University Rating    0\n",
       "SOP                  0\n",
       "LOR                  0\n",
       "CGPA                 0\n",
       "Research             0\n",
       "Chance of Admit      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,0:-1]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "0          337          118                  4  4.5   4.5  9.65         1\n",
       "1          324          107                  4  4.0   4.5  8.87         1\n",
       "2          316          104                  3  3.0   3.5  8.00         1\n",
       "3          322          110                  3  3.5   2.5  8.67         1\n",
       "4          314          103                  2  2.0   3.0  8.21         0\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "495        332          108                  5  4.5   4.0  9.02         1\n",
       "496        337          117                  5  5.0   5.0  9.87         1\n",
       "497        330          120                  5  4.5   5.0  9.56         1\n",
       "498        312          103                  4  4.0   5.0  8.43         0\n",
       "499        327          113                  4  4.5   4.5  9.04         0\n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.92\n",
       "1      0.76\n",
       "2      0.72\n",
       "3      0.80\n",
       "4      0.65\n",
       "       ... \n",
       "495    0.87\n",
       "496    0.96\n",
       "497    0.93\n",
       "498    0.73\n",
       "499    0.84\n",
       "Name: Chance of Admit , Length: 500, dtype: float64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>310</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>318</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>300</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>300</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>322</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>307</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>326</td>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>300</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
       "238        310          104                  3  2.0   3.5  8.37         0\n",
       "438        318          110                  1  2.5   3.5  8.54         1\n",
       "475        300          101                  3  3.5   2.5  7.88         0\n",
       "58         300           99                  1  3.0   2.0  6.80         1\n",
       "380        322          104                  3  3.5   4.0  8.84         1\n",
       "..         ...          ...                ...  ...   ...   ...       ...\n",
       "255        307          110                  4  4.0   4.5  8.37         0\n",
       "72         321          111                  5  5.0   5.0  9.45         1\n",
       "396        325          107                  3  3.0   3.5  9.11         1\n",
       "235        326          111                  5  4.5   4.0  9.23         1\n",
       "37         300          105                  1  1.0   2.0  7.80         0\n",
       "\n",
       "[400 rows x 7 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled= scalar.fit_transform(X_train)\n",
    "X_test_scaled = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(7,activation='relu',input_dim=7))\n",
    "model.add(Dense(7,activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120 (480.00 Byte)\n",
      "Trainable params: 120 (480.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 12ms/step - loss: 0.6939 - val_loss: 0.7024\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6131 - val_loss: 0.6213\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5404 - val_loss: 0.5516\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4787 - val_loss: 0.4907\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4217 - val_loss: 0.4352\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3673 - val_loss: 0.3740\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3059 - val_loss: 0.2975\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2312 - val_loss: 0.2094\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1561 - val_loss: 0.1315\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0937 - val_loss: 0.0735\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0510 - val_loss: 0.0378\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0203\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0139\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0125\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0094\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0091\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0089\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0087\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0086\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0077\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0073\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0071\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0070\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0069\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0068\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0065\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0064\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0061\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0059\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0050\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0049\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train_scaled,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918027522448402"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d5fd1b4490>]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
