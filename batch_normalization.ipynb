{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_excel(r'D:\\copy of htdocs\\practice\\Python\\200days\\Day185 Deep Learning Day 15\\concentric_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.95</td>\n",
       "      <td>2.740</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>-2.160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.67</td>\n",
       "      <td>-0.942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.56</td>\n",
       "      <td>-1.850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X      Y  class\n",
       "0  0.70 -0.247      0\n",
       "1 -3.95  2.740      1\n",
       "2  0.15 -2.160      1\n",
       "3 -1.67 -0.942      1\n",
       "4  2.56 -1.850      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2963b46e5d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['X'],df['Y'],c=df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:2].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15 (60.00 Byte)\n",
      "Trainable params: 15 (60.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(2,activation='relu',input_dim=2))\n",
    "model.add(Dense(2,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 643ms/step - loss: 0.6564 - accuracy: 0.2500 - val_loss: 0.6698 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6552 - accuracy: 0.7500 - val_loss: 0.6719 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6540 - accuracy: 0.7500 - val_loss: 0.6740 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6528 - accuracy: 0.7500 - val_loss: 0.6761 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6517 - accuracy: 0.7500 - val_loss: 0.6782 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6507 - accuracy: 0.7500 - val_loss: 0.6802 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6496 - accuracy: 0.7500 - val_loss: 0.6823 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6485 - accuracy: 0.7500 - val_loss: 0.6845 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6474 - accuracy: 0.7500 - val_loss: 0.6866 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6462 - accuracy: 0.7500 - val_loss: 0.6882 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6451 - accuracy: 0.7500 - val_loss: 0.6877 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6440 - accuracy: 0.7500 - val_loss: 0.6872 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6429 - accuracy: 0.7500 - val_loss: 0.6867 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6418 - accuracy: 0.7500 - val_loss: 0.6862 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6406 - accuracy: 0.7500 - val_loss: 0.6857 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6395 - accuracy: 0.7500 - val_loss: 0.6852 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6384 - accuracy: 0.7500 - val_loss: 0.6847 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6374 - accuracy: 0.7500 - val_loss: 0.6842 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6365 - accuracy: 0.7500 - val_loss: 0.6837 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6357 - accuracy: 0.7500 - val_loss: 0.6832 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6347 - accuracy: 0.7500 - val_loss: 0.6827 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6337 - accuracy: 0.7500 - val_loss: 0.6822 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6324 - accuracy: 0.7500 - val_loss: 0.6817 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6310 - accuracy: 0.7500 - val_loss: 0.6813 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6296 - accuracy: 0.7500 - val_loss: 0.6808 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6282 - accuracy: 0.7500 - val_loss: 0.6803 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6267 - accuracy: 0.7500 - val_loss: 0.6798 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6252 - accuracy: 0.7500 - val_loss: 0.6793 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6237 - accuracy: 0.7500 - val_loss: 0.6788 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6222 - accuracy: 0.7500 - val_loss: 0.6783 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6207 - accuracy: 0.7500 - val_loss: 0.6779 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6192 - accuracy: 0.7500 - val_loss: 0.6774 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6177 - accuracy: 0.7500 - val_loss: 0.6769 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6162 - accuracy: 0.7500 - val_loss: 0.6764 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6147 - accuracy: 0.7500 - val_loss: 0.6760 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6132 - accuracy: 0.7500 - val_loss: 0.6755 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6117 - accuracy: 0.7500 - val_loss: 0.6750 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6102 - accuracy: 0.7500 - val_loss: 0.6745 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6088 - accuracy: 0.7500 - val_loss: 0.6740 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6073 - accuracy: 0.7500 - val_loss: 0.6731 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6057 - accuracy: 0.7500 - val_loss: 0.6720 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6042 - accuracy: 0.7500 - val_loss: 0.6710 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6026 - accuracy: 0.7500 - val_loss: 0.6700 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6011 - accuracy: 0.7500 - val_loss: 0.6689 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5995 - accuracy: 0.7500 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5980 - accuracy: 0.7500 - val_loss: 0.6668 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5965 - accuracy: 0.7500 - val_loss: 0.6657 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5950 - accuracy: 0.7500 - val_loss: 0.6646 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5935 - accuracy: 0.7500 - val_loss: 0.6635 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5920 - accuracy: 0.7500 - val_loss: 0.6624 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5906 - accuracy: 0.7500 - val_loss: 0.6613 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5891 - accuracy: 0.7500 - val_loss: 0.6602 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5877 - accuracy: 0.7500 - val_loss: 0.6592 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5863 - accuracy: 0.7500 - val_loss: 0.6581 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5849 - accuracy: 0.7500 - val_loss: 0.6570 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5836 - accuracy: 0.7500 - val_loss: 0.6559 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5822 - accuracy: 0.7500 - val_loss: 0.6549 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5809 - accuracy: 0.7500 - val_loss: 0.6538 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5795 - accuracy: 0.7500 - val_loss: 0.6528 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5782 - accuracy: 0.7500 - val_loss: 0.6517 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5770 - accuracy: 0.7500 - val_loss: 0.6507 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5757 - accuracy: 0.7500 - val_loss: 0.6496 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5745 - accuracy: 0.7500 - val_loss: 0.6486 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5732 - accuracy: 0.7500 - val_loss: 0.6476 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5720 - accuracy: 0.7500 - val_loss: 0.6465 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5708 - accuracy: 0.7500 - val_loss: 0.6455 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5696 - accuracy: 0.7500 - val_loss: 0.6445 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5685 - accuracy: 0.7500 - val_loss: 0.6435 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5673 - accuracy: 0.7500 - val_loss: 0.6425 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5662 - accuracy: 0.7500 - val_loss: 0.6415 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5651 - accuracy: 0.7500 - val_loss: 0.6405 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5640 - accuracy: 0.7500 - val_loss: 0.6395 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5629 - accuracy: 0.7500 - val_loss: 0.6385 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5618 - accuracy: 0.7500 - val_loss: 0.6375 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5608 - accuracy: 0.7500 - val_loss: 0.6366 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5597 - accuracy: 0.7500 - val_loss: 0.6356 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5587 - accuracy: 0.7500 - val_loss: 0.6346 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5577 - accuracy: 0.7500 - val_loss: 0.6337 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5567 - accuracy: 0.7500 - val_loss: 0.6327 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5558 - accuracy: 0.7500 - val_loss: 0.6318 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5548 - accuracy: 0.7500 - val_loss: 0.6308 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5538 - accuracy: 0.7500 - val_loss: 0.6299 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5529 - accuracy: 0.7500 - val_loss: 0.6290 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5520 - accuracy: 0.7500 - val_loss: 0.6280 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5511 - accuracy: 0.7500 - val_loss: 0.6271 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5502 - accuracy: 0.7500 - val_loss: 0.6262 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5493 - accuracy: 0.7500 - val_loss: 0.6253 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5485 - accuracy: 0.7500 - val_loss: 0.6244 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5476 - accuracy: 0.7500 - val_loss: 0.6235 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5468 - accuracy: 0.7500 - val_loss: 0.6226 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5459 - accuracy: 0.7500 - val_loss: 0.6217 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5451 - accuracy: 0.7500 - val_loss: 0.6208 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5443 - accuracy: 0.7500 - val_loss: 0.6199 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5435 - accuracy: 0.7500 - val_loss: 0.6190 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5427 - accuracy: 0.7500 - val_loss: 0.6182 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5420 - accuracy: 0.7500 - val_loss: 0.6173 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5412 - accuracy: 0.7500 - val_loss: 0.6164 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5405 - accuracy: 0.7500 - val_loss: 0.6155 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5397 - accuracy: 0.7500 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5390 - accuracy: 0.7500 - val_loss: 0.6138 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5383 - accuracy: 0.7500 - val_loss: 0.6130 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5376 - accuracy: 0.7500 - val_loss: 0.6121 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5369 - accuracy: 0.7500 - val_loss: 0.6113 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5362 - accuracy: 0.7500 - val_loss: 0.6104 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5355 - accuracy: 0.7500 - val_loss: 0.6096 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5349 - accuracy: 0.7500 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5342 - accuracy: 0.7500 - val_loss: 0.6079 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5336 - accuracy: 0.7500 - val_loss: 0.6071 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5329 - accuracy: 0.7500 - val_loss: 0.6063 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5323 - accuracy: 0.7500 - val_loss: 0.6054 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5317 - accuracy: 0.7500 - val_loss: 0.6046 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5311 - accuracy: 0.7500 - val_loss: 0.6038 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5305 - accuracy: 0.7500 - val_loss: 0.6030 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5299 - accuracy: 0.7500 - val_loss: 0.6022 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5293 - accuracy: 0.7500 - val_loss: 0.6014 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5287 - accuracy: 0.7500 - val_loss: 0.6006 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5282 - accuracy: 0.7500 - val_loss: 0.5998 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5276 - accuracy: 0.7500 - val_loss: 0.5990 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5270 - accuracy: 0.7500 - val_loss: 0.5982 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5265 - accuracy: 0.7500 - val_loss: 0.5974 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5260 - accuracy: 0.7500 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5254 - accuracy: 0.7500 - val_loss: 0.5958 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5249 - accuracy: 0.7500 - val_loss: 0.5951 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5244 - accuracy: 0.7500 - val_loss: 0.5943 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5239 - accuracy: 0.7500 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5234 - accuracy: 0.7500 - val_loss: 0.5927 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5229 - accuracy: 0.7500 - val_loss: 0.5920 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5224 - accuracy: 0.7500 - val_loss: 0.5912 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5219 - accuracy: 0.7500 - val_loss: 0.5904 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5215 - accuracy: 0.7500 - val_loss: 0.5897 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5210 - accuracy: 0.7500 - val_loss: 0.5889 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5205 - accuracy: 0.7500 - val_loss: 0.5882 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5201 - accuracy: 0.7500 - val_loss: 0.5874 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5196 - accuracy: 0.7500 - val_loss: 0.5867 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5192 - accuracy: 0.7500 - val_loss: 0.5859 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5188 - accuracy: 0.7500 - val_loss: 0.5852 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5183 - accuracy: 0.7500 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5179 - accuracy: 0.7500 - val_loss: 0.5837 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5175 - accuracy: 0.7500 - val_loss: 0.5830 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5171 - accuracy: 0.7500 - val_loss: 0.5822 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5167 - accuracy: 0.7500 - val_loss: 0.5815 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5163 - accuracy: 0.7500 - val_loss: 0.5808 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5159 - accuracy: 0.7500 - val_loss: 0.5801 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5155 - accuracy: 0.7500 - val_loss: 0.5793 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5151 - accuracy: 0.7500 - val_loss: 0.5786 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5147 - accuracy: 0.7500 - val_loss: 0.5779 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5143 - accuracy: 0.7500 - val_loss: 0.5772 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5140 - accuracy: 0.7500 - val_loss: 0.5765 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5136 - accuracy: 0.7500 - val_loss: 0.5758 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5132 - accuracy: 0.7500 - val_loss: 0.5750 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5129 - accuracy: 0.7500 - val_loss: 0.5743 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5125 - accuracy: 0.7500 - val_loss: 0.5736 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5122 - accuracy: 0.7500 - val_loss: 0.5729 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5118 - accuracy: 0.7500 - val_loss: 0.5722 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5115 - accuracy: 0.7500 - val_loss: 0.5715 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5111 - accuracy: 0.7500 - val_loss: 0.5709 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5108 - accuracy: 0.7500 - val_loss: 0.5702 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5105 - accuracy: 0.7500 - val_loss: 0.5695 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5102 - accuracy: 0.7500 - val_loss: 0.5688 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5098 - accuracy: 0.7500 - val_loss: 0.5681 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5095 - accuracy: 0.7500 - val_loss: 0.5674 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5092 - accuracy: 0.7500 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5089 - accuracy: 0.7500 - val_loss: 0.5661 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5086 - accuracy: 0.7500 - val_loss: 0.5654 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5083 - accuracy: 0.7500 - val_loss: 0.5647 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5080 - accuracy: 0.7500 - val_loss: 0.5640 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5077 - accuracy: 0.7500 - val_loss: 0.5634 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5074 - accuracy: 0.7500 - val_loss: 0.5627 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5071 - accuracy: 0.7500 - val_loss: 0.5620 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.5614 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5065 - accuracy: 0.7500 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5063 - accuracy: 0.7500 - val_loss: 0.5601 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.5594 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5057 - accuracy: 0.7500 - val_loss: 0.5588 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5055 - accuracy: 0.7500 - val_loss: 0.5581 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5052 - accuracy: 0.7500 - val_loss: 0.5575 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5049 - accuracy: 0.7500 - val_loss: 0.5568 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5047 - accuracy: 0.7500 - val_loss: 0.5562 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5044 - accuracy: 0.7500 - val_loss: 0.5555 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5042 - accuracy: 0.7500 - val_loss: 0.5549 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5039 - accuracy: 0.7500 - val_loss: 0.5542 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5037 - accuracy: 0.7500 - val_loss: 0.5536 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5034 - accuracy: 0.7500 - val_loss: 0.5530 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5032 - accuracy: 0.7500 - val_loss: 0.5523 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5029 - accuracy: 0.7500 - val_loss: 0.5517 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5027 - accuracy: 0.7500 - val_loss: 0.5511 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5025 - accuracy: 0.7500 - val_loss: 0.5504 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5022 - accuracy: 0.7500 - val_loss: 0.5498 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5020 - accuracy: 0.7500 - val_loss: 0.5492 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5018 - accuracy: 0.7500 - val_loss: 0.5486 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.5015 - accuracy: 0.7500 - val_loss: 0.5479 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5013 - accuracy: 0.7500 - val_loss: 0.5473 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5011 - accuracy: 0.7500 - val_loss: 0.5467 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5009 - accuracy: 0.7500 - val_loss: 0.5461 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5007 - accuracy: 0.7500 - val_loss: 0.5455 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5005 - accuracy: 0.7500 - val_loss: 0.5449 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5003 - accuracy: 0.7500 - val_loss: 0.5443 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5000 - accuracy: 0.7500 - val_loss: 0.5437 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4998 - accuracy: 0.7500 - val_loss: 0.5431 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4996 - accuracy: 0.7500 - val_loss: 0.5425 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(X,y,epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 3)                 9         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 3)                 12        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 8         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 2)                 8         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40 (160.00 Byte)\n",
      "Trainable params: 30 (120.00 Byte)\n",
      "Non-trainable params: 10 (40.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(3,activation='relu',input_dim=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 890ms/step - loss: 0.5150 - accuracy: 0.7500 - val_loss: 0.6914 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5046 - accuracy: 0.7500 - val_loss: 0.6897 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4944 - accuracy: 0.7500 - val_loss: 0.6882 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4846 - accuracy: 0.7500 - val_loss: 0.6868 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4751 - accuracy: 0.7500 - val_loss: 0.6854 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4660 - accuracy: 1.0000 - val_loss: 0.6842 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4573 - accuracy: 1.0000 - val_loss: 0.6831 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4491 - accuracy: 1.0000 - val_loss: 0.6821 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4413 - accuracy: 1.0000 - val_loss: 0.6812 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4341 - accuracy: 1.0000 - val_loss: 0.6803 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4273 - accuracy: 1.0000 - val_loss: 0.6795 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4211 - accuracy: 1.0000 - val_loss: 0.6788 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4152 - accuracy: 1.0000 - val_loss: 0.6782 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4099 - accuracy: 1.0000 - val_loss: 0.6776 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4049 - accuracy: 1.0000 - val_loss: 0.6770 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4003 - accuracy: 1.0000 - val_loss: 0.6765 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3961 - accuracy: 1.0000 - val_loss: 0.6761 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3922 - accuracy: 1.0000 - val_loss: 0.6756 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3887 - accuracy: 1.0000 - val_loss: 0.6752 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3853 - accuracy: 1.0000 - val_loss: 0.6749 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3836 - accuracy: 1.0000 - val_loss: 0.6744 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3822 - accuracy: 1.0000 - val_loss: 0.6739 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3809 - accuracy: 1.0000 - val_loss: 0.6733 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3795 - accuracy: 1.0000 - val_loss: 0.6727 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3783 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3770 - accuracy: 1.0000 - val_loss: 0.6712 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3757 - accuracy: 1.0000 - val_loss: 0.6704 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3745 - accuracy: 1.0000 - val_loss: 0.6696 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3733 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3721 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3709 - accuracy: 1.0000 - val_loss: 0.6668 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3698 - accuracy: 1.0000 - val_loss: 0.6658 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3686 - accuracy: 1.0000 - val_loss: 0.6648 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3675 - accuracy: 1.0000 - val_loss: 0.6637 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3664 - accuracy: 1.0000 - val_loss: 0.6627 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3653 - accuracy: 1.0000 - val_loss: 0.6616 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3642 - accuracy: 1.0000 - val_loss: 0.6605 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3631 - accuracy: 1.0000 - val_loss: 0.6594 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3620 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3610 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3599 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3588 - accuracy: 1.0000 - val_loss: 0.6548 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3578 - accuracy: 1.0000 - val_loss: 0.6537 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3567 - accuracy: 1.0000 - val_loss: 0.6525 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3556 - accuracy: 1.0000 - val_loss: 0.6514 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3546 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3535 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3525 - accuracy: 1.0000 - val_loss: 0.6479 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3514 - accuracy: 1.0000 - val_loss: 0.6467 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3504 - accuracy: 1.0000 - val_loss: 0.6456 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.3493 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3483 - accuracy: 1.0000 - val_loss: 0.6433 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3472 - accuracy: 1.0000 - val_loss: 0.6422 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3462 - accuracy: 1.0000 - val_loss: 0.6411 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3452 - accuracy: 1.0000 - val_loss: 0.6400 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3441 - accuracy: 1.0000 - val_loss: 0.6389 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3431 - accuracy: 1.0000 - val_loss: 0.6378 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3421 - accuracy: 1.0000 - val_loss: 0.6367 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3410 - accuracy: 1.0000 - val_loss: 0.6356 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3400 - accuracy: 1.0000 - val_loss: 0.6346 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3390 - accuracy: 1.0000 - val_loss: 0.6335 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3380 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3369 - accuracy: 1.0000 - val_loss: 0.6315 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3359 - accuracy: 1.0000 - val_loss: 0.6305 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3349 - accuracy: 1.0000 - val_loss: 0.6295 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3339 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3329 - accuracy: 1.0000 - val_loss: 0.6276 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3319 - accuracy: 1.0000 - val_loss: 0.6266 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3309 - accuracy: 1.0000 - val_loss: 0.6257 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3299 - accuracy: 1.0000 - val_loss: 0.6247 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3290 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3280 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3270 - accuracy: 1.0000 - val_loss: 0.6220 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3260 - accuracy: 1.0000 - val_loss: 0.6212 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3250 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3241 - accuracy: 1.0000 - val_loss: 0.6195 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3231 - accuracy: 1.0000 - val_loss: 0.6186 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3221 - accuracy: 1.0000 - val_loss: 0.6178 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3212 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3202 - accuracy: 1.0000 - val_loss: 0.6162 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3192 - accuracy: 1.0000 - val_loss: 0.6154 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3183 - accuracy: 1.0000 - val_loss: 0.6146 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3173 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3164 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3154 - accuracy: 1.0000 - val_loss: 0.6124 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3145 - accuracy: 1.0000 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3135 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3126 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3116 - accuracy: 1.0000 - val_loss: 0.6094 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3101 - accuracy: 1.0000 - val_loss: 0.6084 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3083 - accuracy: 1.0000 - val_loss: 0.6073 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3064 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3043 - accuracy: 1.0000 - val_loss: 0.6050 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3021 - accuracy: 1.0000 - val_loss: 0.6037 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2998 - accuracy: 1.0000 - val_loss: 0.6024 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2974 - accuracy: 1.0000 - val_loss: 0.6011 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2949 - accuracy: 1.0000 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2924 - accuracy: 1.0000 - val_loss: 0.5983 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2898 - accuracy: 1.0000 - val_loss: 0.5969 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2871 - accuracy: 1.0000 - val_loss: 0.5955 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2844 - accuracy: 1.0000 - val_loss: 0.5941 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2790 - accuracy: 1.0000 - val_loss: 0.5926 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2711 - accuracy: 1.0000 - val_loss: 0.5911 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2617 - accuracy: 1.0000 - val_loss: 0.5894 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2510 - accuracy: 1.0000 - val_loss: 0.5878 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2404 - accuracy: 1.0000 - val_loss: 0.5865 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2309 - accuracy: 1.0000 - val_loss: 0.5843 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2221 - accuracy: 1.0000 - val_loss: 0.5813 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2151 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.5773 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2086 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2074 - accuracy: 1.0000 - val_loss: 0.5778 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2047 - accuracy: 1.0000 - val_loss: 0.5799 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1996 - accuracy: 1.0000 - val_loss: 0.5831 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1927 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1861 - accuracy: 1.0000 - val_loss: 0.5916 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1805 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1769 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1761 - accuracy: 1.0000 - val_loss: 0.6023 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1766 - accuracy: 1.0000 - val_loss: 0.6050 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1766 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1757 - accuracy: 1.0000 - val_loss: 0.6098 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1741 - accuracy: 1.0000 - val_loss: 0.6120 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1720 - accuracy: 1.0000 - val_loss: 0.6141 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1701 - accuracy: 1.0000 - val_loss: 0.6161 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1687 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1681 - accuracy: 1.0000 - val_loss: 0.6203 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1681 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1679 - accuracy: 1.0000 - val_loss: 0.6249 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1672 - accuracy: 1.0000 - val_loss: 0.6273 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1658 - accuracy: 1.0000 - val_loss: 0.6299 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1641 - accuracy: 1.0000 - val_loss: 0.6324 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1625 - accuracy: 1.0000 - val_loss: 0.6351 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1613 - accuracy: 1.0000 - val_loss: 0.6377 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1604 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1596 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1588 - accuracy: 1.0000 - val_loss: 0.6452 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1579 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1568 - accuracy: 1.0000 - val_loss: 0.6500 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1556 - accuracy: 1.0000 - val_loss: 0.6517 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1545 - accuracy: 1.0000 - val_loss: 0.6530 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1535 - accuracy: 1.0000 - val_loss: 0.6543 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1526 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1518 - accuracy: 1.0000 - val_loss: 0.6574 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1511 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1504 - accuracy: 1.0000 - val_loss: 0.6615 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1495 - accuracy: 1.0000 - val_loss: 0.6638 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1487 - accuracy: 1.0000 - val_loss: 0.6663 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1478 - accuracy: 1.0000 - val_loss: 0.6689 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1470 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1462 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1455 - accuracy: 1.0000 - val_loss: 0.6767 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1449 - accuracy: 1.0000 - val_loss: 0.6791 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1442 - accuracy: 1.0000 - val_loss: 0.6814 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1435 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1428 - accuracy: 1.0000 - val_loss: 0.6857 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1421 - accuracy: 1.0000 - val_loss: 0.6878 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1414 - accuracy: 1.0000 - val_loss: 0.6898 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1407 - accuracy: 1.0000 - val_loss: 0.6919 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1400 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1394 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1388 - accuracy: 1.0000 - val_loss: 0.6987 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1381 - accuracy: 1.0000 - val_loss: 0.7013 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1375 - accuracy: 1.0000 - val_loss: 0.7040 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1368 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1362 - accuracy: 1.0000 - val_loss: 0.7096 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1355 - accuracy: 1.0000 - val_loss: 0.7125 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1349 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1343 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1337 - accuracy: 1.0000 - val_loss: 0.7212 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1330 - accuracy: 1.0000 - val_loss: 0.7240 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1324 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1318 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1312 - accuracy: 1.0000 - val_loss: 0.7323 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1306 - accuracy: 1.0000 - val_loss: 0.7351 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1300 - accuracy: 1.0000 - val_loss: 0.7379 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1294 - accuracy: 1.0000 - val_loss: 0.7408 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1288 - accuracy: 1.0000 - val_loss: 0.7438 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1283 - accuracy: 1.0000 - val_loss: 0.7469 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1277 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1271 - accuracy: 1.0000 - val_loss: 0.7533 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1266 - accuracy: 1.0000 - val_loss: 0.7566 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1260 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 0.7633 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1249 - accuracy: 1.0000 - val_loss: 0.7668 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1243 - accuracy: 1.0000 - val_loss: 0.7702 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1238 - accuracy: 1.0000 - val_loss: 0.7736 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1233 - accuracy: 1.0000 - val_loss: 0.7770 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 0.7805 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1222 - accuracy: 1.0000 - val_loss: 0.7839 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1217 - accuracy: 1.0000 - val_loss: 0.7873 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1211 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1206 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1201 - accuracy: 1.0000 - val_loss: 0.7979 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.8016 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1191 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1185 - accuracy: 1.0000 - val_loss: 0.8091 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1180 - accuracy: 1.0000 - val_loss: 0.8129 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1175 - accuracy: 1.0000 - val_loss: 0.8168 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1170 - accuracy: 1.0000 - val_loss: 0.8208 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X,y,epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2963ea7ee10>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['val_accuracy'],color='black')\n",
    "plt.plot(history2.history['val_accuracy'],color='green')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
